{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5642719c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00ad063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b94e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509810e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3d3fda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba7d7de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04df9f29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d983d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bc3f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph of Income Distribution\n",
    "# Clean NA values in the \"AMT_INCOME_TOTAL\" column\n",
    "df_cleaned = df_e.dropna(subset=['AMT_INCOME_TOTAL'])\n",
    "\n",
    "# Convert the \"AMT_INCOME_TOTAL\" column to numeric\n",
    "df_cleaned['AMT_INCOME_TOTAL'] = pd.to_numeric(df_cleaned['AMT_INCOME_TOTAL'], errors='coerce')\n",
    "\n",
    "# Cap the income at 1 million\n",
    "df_cleaned['AMT_INCOME_TOTAL'] = df_cleaned['AMT_INCOME_TOTAL'].clip(upper=1000000)\n",
    "\n",
    "# Convert income to hundreds of thousands for the x-axis\n",
    "df_cleaned['AMT_INCOME_TOTAL_hundreds_thousands'] = df_cleaned['AMT_INCOME_TOTAL'] / 100000\n",
    "\n",
    "# Plot a histogram\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.hist(df_cleaned['AMT_INCOME_TOTAL_hundreds_thousands'], bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "plt.title('Income Explosion')\n",
    "plt.xlabel('Income (Hundreds of Thousands)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c0f184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Plot top 30 positive correlations\n",
    "axes[0].barh(top_positive_correlations.index, top_positive_correlations.values, color='red')\n",
    "axes[0].set_title('Top 30 Positive Correlations')\n",
    "axes[0].set_xlabel('Correlation')\n",
    "axes[0].set_ylabel('Features')\n",
    "\n",
    "# Plot top 30 negative correlations\n",
    "axes[1].barh(top_negative_correlations.index, top_negative_correlations.values, color='gray')\n",
    "axes[1].set_title('Top 30 Negative Correlations')\n",
    "axes[1].set_xlabel('Correlation')\n",
    "axes[1].set_ylabel('Features')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b00109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph of top 10 missing data columns\n",
    "\n",
    "# Selecting only the top 20 rows\n",
    "top_20_missing_data = missing_data.head(20)\n",
    "\n",
    "# Increase the figure size to accommodate more space for labels\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plotting\n",
    "top_20_missing_data.plot(kind='barh', color='red')  # Horizontal bar plot\n",
    "\n",
    "# Add title and labels with smaller font size\n",
    "plt.title('Top 20 Columns with Missing Data', fontsize=14)\n",
    "plt.xlabel('Percentage Missing', fontsize=12)\n",
    "plt.ylabel('Columns', fontsize=12)\n",
    "\n",
    "# Decrease the font size of the ticks\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "# Add more space between bars\n",
    "plt.tight_layout(pad=3.0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81d09b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your features (X) and target variable (y) based on your EDA\n",
    "X_train = df_downsampled.drop(columns=['TARGET'])\n",
    "y_train = df_downsampled['TARGET']\n",
    "\n",
    "df_e_encoded.drop(columns=['TARGET'], inplace=True)\n",
    "\n",
    "X_test = df_e_encoded\n",
    "y_test = None  # You don't have the ground truth labels for the test set\n",
    "\n",
    "\n",
    "# Check the shape of the resulting sets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc9e637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'NAME_CONTRACT_TYPE' column from both X_train and X_val\n",
    "#X_train.drop(columns=['ORGANIZATION_TYPE'], inplace=True, errors='ignore')  \n",
    "#X_train.drop(columns=['NAME_CASH_LOAN_PURPOSE'], inplace=True, errors='ignore') \n",
    "#X_train.drop(columns=['NAME_GOODS_CATEGORY'], inplace=True, errors='ignore') \n",
    "#X_val.drop(columns=['ORGANIZATION_TYPE'], inplace=True, errors='ignore')  \n",
    "#X_val.drop(columns=['NAME_CASH_LOAN_PURPOSE'], inplace=True, errors='ignore')  \n",
    "#X_val.drop(columns=['NAME_GOODS_CATEGORY'], inplace=True, errors='ignore') \n",
    "# Initialize logistic regression model\n",
    "# model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Fit the model on training data\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on validation set\n",
    "# y_pred = model.predict(X_val)\n",
    "# y_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "# accuracy = accuracy_score(y_val, y_pred)\n",
    "# recall = recall_score(y_val, y_pred)\n",
    "# f1 = f1_score(y_val, y_pred)\n",
    "# roc_auc = roc_auc_score(y_val, y_proba)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "# print(\"Performance Metrics:\")\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "# print(\"Recall:\", recall)\n",
    "# print(\"F1-score:\", f1)\n",
    "# print(\"AUC-ROC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a696cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on Validation Set\n",
    "\n",
    "# Define your features (X) and target variable (y) based on your EDA\n",
    "X = df_downsampled.drop(columns=['TARGET'])\n",
    "y = df_downsampled['TARGET']\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the shape of the resulting sets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape, y_val.shape)\n",
    "\n",
    "random_forest = RandomForestClassifier(\n",
    "    n_estimators=500,  # Number of trees in the forest\n",
    "    max_depth=20,      # Maximum depth of the trees\n",
    "    min_samples_split=4,  # Minimum number of samples required to split a node\n",
    "    min_samples_leaf=2,   # Minimum number of samples required at each leaf node\n",
    "    random_state=144     # Random seed for reproducibility\n",
    ")\n",
    "\n",
    "# Initialize models\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "gradient_boosting = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Fit models\n",
    "random_forest.fit(X_train, y_train)\n",
    "gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = random_forest.predict(X_val)\n",
    "y_pred_gb = gradient_boosting.predict(X_val)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "metrics_rf_gb = [accuracy_score, recall_score, f1_score]\n",
    "\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dded6f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Metrics\n",
    "results['Random Forest'] = {metric.__name__: metric(y_val, y_pred_rf) for metric in metrics_rf_gb}\n",
    "\n",
    "# Gradient Boosting Metrics\n",
    "results['Gradient Boosting'] = {metric.__name__: metric(y_val, y_pred_gb) for metric in metrics_rf_gb}\n",
    "\n",
    "# Print results\n",
    "for model, metrics in results.items():\n",
    "    print(f\"{model} Metrics:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1146ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "random_forest = RandomForestClassifier(\n",
    "    n_estimators=800,  \n",
    "    max_depth=60,      \n",
    "    min_samples_split=2,  \n",
    "    min_samples_leaf=1,   \n",
    "    random_state=144     \n",
    ")\n",
    "\n",
    "gradient_boosting = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Fit models\n",
    "random_forest.fit(X_train, y_train)\n",
    "gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using predict_proba\n",
    "y_pred_rf_proba = random_forest.predict_proba(X_test)[:, 1]  # Probability of positive class\n",
    "y_pred_gb_proba = gradient_boosting.predict_proba(X_test)[:, 1]  # Probability of positive class\n",
    "\n",
    "# Create DataFrame with predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'SK_ID_CURR': df_e_encoded['SK_ID_CURR'],  # Assuming df_e_encoded contains the original data with IDs\n",
    "    'TARGET': y_pred_gb_proba\n",
    "})\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "predictions_df.to_csv('predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e385ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Gradient Boosting model\n",
    "gradient_boosting = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = gradient_boosting.feature_importances_\n",
    "\n",
    "# Create a DataFrame to store feature importances\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,  # Assuming X_train is your feature matrix\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print or save the DataFrame\n",
    "print(importance_df)\n",
    "# importance_df.to_csv('feature_importance.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc22475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Plotting the first 5 features in red\n",
    "plt.bar(importance_df['Feature'][:5], importance_df['Importance'][:5], color='red')\n",
    "# Plotting the second 5 features in gray\n",
    "plt.bar(importance_df['Feature'][5:10], importance_df['Importance'][5:10], color='gray')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Top 10 Feature Importances')\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
